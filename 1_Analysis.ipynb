{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a4df522-dbba-4a1e-b47e-e69a30b36600",
   "metadata": {},
   "source": [
    "# Energy Consumption Prediction for Buildings\n",
    "\n",
    "This notebook aims to predict a building's energy consumption over 2017 and 2018 using the data from 2016 in 4 different consumption categories (electricity, chilled water, steam, hot water) using ASHRAE data, which is our problem statement as well.\n",
    "\n",
    "This is a supervised machine learning model, meaning based on the columns available in the datasets and data from 2016, we are going to train the model to predict energy consumption of a building in each category. Since consumption values are labeled as `meter_reading` and they are continuous, we will apply regression techniques to generate predictions on `meter_reading`.\n",
    "\n",
    "It is a highly debated and popular competition in Kaggle currently, however, my main motivation is to contribute to making energy-efficient buildings by estimating their energy consumption. It seemed like a good start to save our energy for the future!\n",
    "\n",
    "There will be 3 notebooks covering the complete machine learning building pipeline:\n",
    "\n",
    "- **Notebook 1**: Focuses on parts 1 and 2, providing information about the datasets and a detailed EDA.\n",
    "- **Notebook 2**: Covers parts 3, 4, and 5, focusing on building the optimal machine learning model.\n",
    "- **Notebook 3**: Covers parts 6, 7, and 8, focusing on generating predictions with the best model and providing a summary for the whole project.\n",
    "\n",
    "Machine Learning application and building is not a linear and one-time process. The steps above enable me to follow a structured way for an end-to-end machine project flow and preparation for each step ahead. All in all, steps might be modified or revisited according to findings. You can use the table of contents to navigate to each section and visual ðŸ‘‡\n",
    "\n",
    "**Enjoy reading!**\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "### 1. Understand, Clean, and Format Data\n",
    "1.1. Load data into dataframes  \n",
    "1.2. Reduce the memory size  \n",
    "1.3. Information about the training datasets  \n",
    "   - 1.3.1. Building dataset  \n",
    "   - 1.3.2. Weather_train dataset  \n",
    "   - 1.3.3. Train dataset  \n",
    "1.4. Information about the test datasets  \n",
    "   - 1.4.1 Test dataset  \n",
    "   - 1.4.2 Weather_test  \n",
    "1.5. Findings from Understand, Clean, and Format Data  \n",
    "\n",
    "### 2. Exploratory Data Analysis\n",
    "2.1. Distribution of meter reading  \n",
    "   - 2.1.1. Consolidated distribution of meter reading  \n",
    "   - 2.1.2. Consolidated distribution of positive meter reading values  \n",
    "   - 2.1.3. Distribution of meter reading among different meter categories  \n",
    "   - 2.1.4. Distribution of positive meter reading values among different meter categories  \n",
    "   - 2.1.5. Average daily meter reading values over 2016  \n",
    "\n",
    "2.2. Meter reading VS weather_train data  \n",
    "   - 2.2.1. Prepare & merge dataframes  \n",
    "   - 2.2.2. Average daily weather variable values over 2016  \n",
    "   - 2.2.3. Pairplot of meter reading vs weather data  \n",
    "\n",
    "2.3. Meter reading VS building data categorical features  \n",
    "   - 2.3.1. Prepare & merge dataframes  \n",
    "   - 2.3.2. Meter reading distribution among primary uses  \n",
    "   - 2.3.3. Meter reading distribution among site id as violinplot  \n",
    "\n",
    "2.4. Meter reading VS building data continuous features as scatterplots  \n",
    "   - 2.4.1. Scatter plot of meter reading VS square feet  \n",
    "   - 2.4.2. Scatter plot of meter reading VS age of the building  \n",
    "   - 2.4.3. Scatter plot of meter reading VS floor count  \n",
    "\n",
    "2.5. Findings from exploratory data analysis  \n",
    "\n",
    "### 3. Conclusions\n",
    "\n",
    "---\n",
    "\n",
    "## Imports:\n",
    "We will use `numpy` and `pandas` for data munging and manipulation. For visualizations, I will explore some features of `plotly` in this project and create interactive visuals where possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f29b126-4751-4ed5-9bc3-b92411e82a12",
   "metadata": {},
   "source": [
    "## 1. Understand, Clean, and Format Data\n",
    "\n",
    "The very first observation is that the training and test data span across 5 different CSV files. If you look at the data tab of the competition, you will see that:\n",
    "\n",
    "- `train.csv`, `test.csv`, `weather_train.csv`, and `weather_test.csv` are time-series data, with hourly measurements.\n",
    "- `building_metadata.csv` contains the characteristics of a building, such as:\n",
    "   - site ID of the building\n",
    "   - primary use\n",
    "   - square feet\n",
    "   - year built\n",
    "\n",
    "In the weather datasets, there are features related to wind, clouds, temperature, and pressure.\n",
    "\n",
    "- The `weather_train` dataset is measured from **1 Jan 2016** to **1 Jan 2017**.\n",
    "- The `weather_test` dataset spans from **1 Jan 2017** to **1 Jan 2019**.\n",
    "\n",
    "Using the 1-year data, we are going to predict the following 2 years of energy consumption for a building.\n",
    "\n",
    "Looking at the `test.csv` and `sample_submission.csv`, predictions will be based on:\n",
    "\n",
    "- `building_id`\n",
    "- `meter` (energy consumption category)\n",
    "- `timestamp`\n",
    "\n",
    "---\n",
    "\n",
    "### 1.1. Load Data into DataFrames\n",
    "\n",
    "Time-series data will be loaded by parsing the `timestamp` column, enabling the `timestamp` column to be formatted as a **datetime** data type and set as the index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06649aa0-5af4-4315-8319-3e8d55784338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\bhavesh\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\bhavesh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\bhavesh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bhavesh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bhavesh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bhavesh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bhavesh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "import pandas as pd\n",
    "path = r\"D:\\ashrae-energy-prediction\"\n",
    "# Load data\n",
    "building = pd.read_csv(f\"{path}/building_metadata.csv\")\n",
    "weather_train = pd.read_csv(f\"{path}/weather_train.csv\", index_col=1, parse_dates=True)\n",
    "train = pd.read_csv(f\"{path}/train.csv\", index_col=2, parse_dates=True)\n",
    "\n",
    "print(\"Data loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "407da3c2-ff4b-4a0a-a25f-96f748665977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the building dataset is (1449, 6)\n",
      "Size of the weather_train dataset is (139773, 8)\n",
      "Size of the train dataset is (20216100, 3)\n"
     ]
    }
   ],
   "source": [
    "# look at the number of rows and columns\n",
    "print('Size of the building dataset is', building.shape)\n",
    "print('Size of the weather_train dataset is', weather_train.shape)\n",
    "print('Size of the train dataset is', train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82351104-caae-4f9a-aa3f-fc0330990fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values in Building Data:\n",
      " site_id           0\n",
      "building_id       0\n",
      "primary_use       0\n",
      "square_feet       0\n",
      "year_built      774\n",
      "floor_count    1094\n",
      "dtype: int64\n",
      "Missing Values in Weather Data:\n",
      " site_id                   0\n",
      "air_temperature          55\n",
      "cloud_coverage        69173\n",
      "dew_temperature         113\n",
      "precip_depth_1_hr     50289\n",
      "sea_level_pressure    10618\n",
      "wind_direction         6268\n",
      "wind_speed              304\n",
      "dtype: int64\n",
      "Missing Values in Train Data:\n",
      " building_id      0\n",
      "meter            0\n",
      "meter_reading    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing Values in Building Data:\\n\", building.isnull().sum())\n",
    "print(\"Missing Values in Weather Data:\\n\", weather_train.isnull().sum())\n",
    "print(\"Missing Values in Train Data:\\n\", train.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5499232-2b8b-4e3a-a922-0548ff394c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1449 entries, 0 to 1448\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   site_id      1449 non-null   int64  \n",
      " 1   building_id  1449 non-null   int64  \n",
      " 2   primary_use  1449 non-null   object \n",
      " 3   square_feet  1449 non-null   int64  \n",
      " 4   year_built   675 non-null    float64\n",
      " 5   floor_count  355 non-null    float64\n",
      "dtypes: float64(2), int64(3), object(1)\n",
      "memory usage: 68.1+ KB\n",
      "None \n",
      "\n",
      "Weather Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 139773 entries, 2016-01-01 00:00:00 to 2016-12-31 23:00:00\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   site_id             139773 non-null  int64  \n",
      " 1   air_temperature     139718 non-null  float64\n",
      " 2   cloud_coverage      70600 non-null   float64\n",
      " 3   dew_temperature     139660 non-null  float64\n",
      " 4   precip_depth_1_hr   89484 non-null   float64\n",
      " 5   sea_level_pressure  129155 non-null  float64\n",
      " 6   wind_direction      133505 non-null  float64\n",
      " 7   wind_speed          139469 non-null  float64\n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 9.6 MB\n",
      "None \n",
      "\n",
      "Train Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 20216100 entries, 2016-01-01 00:00:00 to 2016-12-31 23:00:00\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   building_id    int64  \n",
      " 1   meter          int64  \n",
      " 2   meter_reading  float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 616.9 MB\n",
      "None \n",
      "\n",
      "Train Data Description:\n",
      "        building_id         meter  meter_reading\n",
      "count  2.021610e+07  2.021610e+07   2.021610e+07\n",
      "mean   7.992780e+02  6.624412e-01   2.117121e+03\n",
      "std    4.269133e+02  9.309921e-01   1.532356e+05\n",
      "min    0.000000e+00  0.000000e+00   0.000000e+00\n",
      "25%    3.930000e+02  0.000000e+00   1.830000e+01\n",
      "50%    8.950000e+02  0.000000e+00   7.877500e+01\n",
      "75%    1.179000e+03  1.000000e+00   2.679840e+02\n",
      "max    1.448000e+03  3.000000e+00   2.190470e+07\n"
     ]
    }
   ],
   "source": [
    "print(\"Building Data Info:\")\n",
    "print(building.info(), \"\\n\")\n",
    "\n",
    "print(\"Weather Data Info:\")\n",
    "print(weather_train.info(), \"\\n\")\n",
    "\n",
    "print(\"Train Data Info:\")\n",
    "print(train.info(), \"\\n\")\n",
    "\n",
    "print(\"Train Data Description:\")\n",
    "print(train.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74986fe3-522f-411a-a17a-7a023c4974f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the weather_test dataset is (277243, 8)\n",
      "Size of the test dataset is (41697600, 3)\n",
      "Size of the sample_submission is (41697600, 2)\n"
     ]
    }
   ],
   "source": [
    "# Path to the dataset\n",
    "path = r\"D:\\ashrae-energy-prediction\"\n",
    "\n",
    "# Load test data\n",
    "weather_test = pd.read_csv(f\"{path}/weather_test.csv\", index_col=1, parse_dates=True)\n",
    "\n",
    "test = pd.read_csv(f\"{path}/test.csv\", index_col=3, parse_dates=True)\n",
    "\n",
    "# Load sample submission data\n",
    "sample_submission = pd.read_csv(f\"{path}/sample_submission.csv\")\n",
    "\n",
    "# Display dataset sizes\n",
    "print('Size of the weather_test dataset is', weather_test.shape)\n",
    "print('Size of the test dataset is', test.shape)\n",
    "print('Size of the sample_submission is', sample_submission.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbc91e77-d4f4-4a9c-aaed-c04e2fd8585b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission not found.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# Delete the sample_submission DataFrame\n",
    "del sample_submission\n",
    "\n",
    "# Run garbage collection to free up memory\n",
    "if 'sample_submission' in globals():\n",
    "    del sample_submission\n",
    "    gc.collect()\n",
    "    print(\"sample_submission deleted successfully.\")\n",
    "else:\n",
    "    print(\"sample_submission not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a675eed4-1564-457c-92a1-cb691e09bc08",
   "metadata": {},
   "source": [
    "## 1.2. Reduce the Memory Size\n",
    "\n",
    "We are dealing with some large datasets here (20 and 40 million rows). To predict with the built model, we have 41 million rows in total.\n",
    "\n",
    "To save space and reduce memory usage, I will delete unused dataframes and use a function that has been built as part of this popular notebook to reduce the memory size of the datasets.\n",
    "\n",
    "The function works by converting data types in such a way that they allocate less space in memory. It will then report the size of the reduction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c89443ad-c778-4147-a785-cdc34425752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to reduce the DF size\n",
    "import numpy as np\n",
    "def reduce_memory_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ac79dcd-b313-47fa-9b69-935afed2c252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.03 Mb (60.3% reduction)\n",
      "Mem. usage decreased to  3.07 Mb (68.1% reduction)\n",
      "Mem. usage decreased to 289.19 Mb (53.1% reduction)\n",
      "Mem. usage decreased to  6.08 Mb (68.1% reduction)\n",
      "Mem. usage decreased to 596.49 Mb (53.1% reduction)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-09 07:00:00</th>\n",
       "      <td>41697595</td>\n",
       "      <td>1444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-09 07:00:00</th>\n",
       "      <td>41697596</td>\n",
       "      <td>1445</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-09 07:00:00</th>\n",
       "      <td>41697597</td>\n",
       "      <td>1446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-09 07:00:00</th>\n",
       "      <td>41697598</td>\n",
       "      <td>1447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-09 07:00:00</th>\n",
       "      <td>41697599</td>\n",
       "      <td>1448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41697600 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       row_id  building_id  meter\n",
       "timestamp                                        \n",
       "2017-01-01 00:00:00         0            0      0\n",
       "2017-01-01 00:00:00         1            1      0\n",
       "2017-01-01 00:00:00         2            2      0\n",
       "2017-01-01 00:00:00         3            3      0\n",
       "2017-01-01 00:00:00         4            4      0\n",
       "...                       ...          ...    ...\n",
       "2018-05-09 07:00:00  41697595         1444      0\n",
       "2018-05-09 07:00:00  41697596         1445      0\n",
       "2018-05-09 07:00:00  41697597         1446      0\n",
       "2018-05-09 07:00:00  41697598         1447      0\n",
       "2018-05-09 07:00:00  41697599         1448      0\n",
       "\n",
       "[41697600 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_memory_usage(building)\n",
    "reduce_memory_usage(weather_train)\n",
    "reduce_memory_usage(train)\n",
    "\n",
    "reduce_memory_usage(weather_test)\n",
    "reduce_memory_usage(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760db6ec-b594-4b0d-a90f-ff9d9df8f2f6",
   "metadata": {},
   "source": [
    "## 1.3. Information about the Training Datasets\n",
    "\n",
    "Since there are 3 CSV files, I will use `pandas_profiling` to get a quick glance of the data for the datasets with less than 1 million rows.\n",
    "\n",
    "`pandas_profiling` is a great library to display information about:\n",
    "\n",
    "- Essentials\n",
    "- Quantile statistics\n",
    "- Descriptive statistics\n",
    "- Most frequent values\n",
    "- Histogram\n",
    "- Correlations (even rejects a column if a collinear correlation is found)\n",
    "\n",
    "It also provides a sample consisting of the first and last rows.\n",
    "\n",
    "The further details about the dataset can be observed by clicking on each tab and using the *Toggle Details* button per column.\n",
    "\n",
    "The best part of `pandas_profiling` is that it delivers a whole bunch of information with just one line of code! If you want to dive deeper into `pandas_profiling`, you can check out their [GitHub page](https://github.com/pandas-profiling/pandas-profiling).\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3.1. Building Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e190ad0-513a-498d-8905-64a6813570ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f46b5ec1-fec2-4de7-97c7-d5e2c91af073",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpp\u001b[49m.ProfileReport(building)\n",
      "\u001b[31mNameError\u001b[39m: name 'pp' is not defined"
     ]
    }
   ],
   "source": [
    "pp.ProfileReport(building)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "327a1548-e860-48a0-8872-aec77b7d9e15",
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticImportError",
     "evalue": "`BaseSettings` has been moved to the `pydantic-settings` package. See https://docs.pydantic.dev/2.11/migration/#basesettings-has-moved-to-pydantic-settings for more details.\n\nFor further information visit https://errors.pydantic.dev/2.11/u/import-error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPydanticImportError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas_profiling\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpandas-profiling is installed and working!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas_profiling\\__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"Main module of pandas-profiling.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03m.. include:: ../../README.md\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas_profiling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontroller\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pandas_decorator\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas_profiling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprofile_report\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas_profiling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas_profiling\\controller\\pandas_decorator.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"This file add the decorator on the DataFrame object.\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas_profiling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprofile_report\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprofile_report\u001b[39m(df: DataFrame, **kwargs) -> ProfileReport:\n\u001b[32m      8\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Profile a DataFrame.\u001b[39;00m\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m \u001b[33;03m        A ProfileReport of the DataFrame.\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas_profiling\\profile_report.py:13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvisions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VisionsTypeset\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas_profiling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Config, Settings\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas_profiling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexpectations_report\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExpectationsReport\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas_profiling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malerts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AlertType\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas_profiling\\config.py:5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Enum\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Optional\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, BaseSettings, Field\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_merge_dictionaries\u001b[39m(dict1: \u001b[38;5;28mdict\u001b[39m, dict2: \u001b[38;5;28mdict\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m      9\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[33;03m    Recursive merge dictionaries.\u001b[39;00m\n\u001b[32m     11\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \u001b[33;03m    :return: Merged dictionary\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\__init__.py:426\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr_name)\u001b[39m\n\u001b[32m    424\u001b[39m dynamic_attr = _dynamic_imports.get(attr_name)\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dynamic_attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_getattr_migration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m package, module_name = dynamic_attr\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m module_name == \u001b[33m'\u001b[39m\u001b[33m__module__\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\_migration.py:296\u001b[39m, in \u001b[36mgetattr_migration.<locals>.wrapper\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m    294\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m import_string(REDIRECT_TO_V1[import_path])\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m import_path == \u001b[33m'\u001b[39m\u001b[33mpydantic:BaseSettings\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticImportError(\n\u001b[32m    297\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m`BaseSettings` has been moved to the `pydantic-settings` package. \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    298\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mSee https://docs.pydantic.dev/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion_short()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/migration/#basesettings-has-moved-to-pydantic-settings \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    299\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mfor more details.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    300\u001b[39m     )\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m import_path \u001b[38;5;129;01min\u001b[39;00m REMOVED_IN_V2:\n\u001b[32m    302\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticImportError(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimport_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` has been removed in V2.\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mPydanticImportError\u001b[39m: `BaseSettings` has been moved to the `pydantic-settings` package. See https://docs.pydantic.dev/2.11/migration/#basesettings-has-moved-to-pydantic-settings for more details.\n\nFor further information visit https://errors.pydantic.dev/2.11/u/import-error"
     ]
    }
   ],
   "source": [
    "import pandas_profiling\n",
    "print(\"pandas-profiling is installed and working!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f422174-4bdd-415a-b4e9-2f2bd92a29ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   site_id  building_id primary_use  square_feet  year_built  floor_count\n",
      "0        0            0   Education         7432      2008.0          NaN\n",
      "1        0            1   Education         2720      2004.0          NaN\n",
      "2        0            2   Education         5376      1991.0          NaN\n",
      "3        0            3   Education        23685      2002.0          NaN\n",
      "4        0            4   Education       116607      1975.0          NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = r\"D:\\ashrae-energy-prediction\"  # Define the folder path\n",
    "\n",
    "# Correct f-string usage\n",
    "building = pd.read_csv(f\"{path}/building_metadata.csv\")  \n",
    "\n",
    "print(building.head())  # Check if the data is loaded correctly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18598ee7-7b54-40b7-84b6-b067983a96b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature: site_id                             |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                   | [ 14%]   00:00 -> (00:00 left)"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'VisibleDeprecationWarning'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msweetviz\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msv\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Generate the report\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m building_report = \u001b[43msv\u001b[49m\u001b[43m.\u001b[49m\u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Extract key insights\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸ”¹ Summary from the Report:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sweetviz\\sv_public.py:12\u001b[39m, in \u001b[36manalyze\u001b[39m\u001b[34m(source, target_feat, feat_cfg, pairwise_analysis)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34manalyze\u001b[39m(source: Union[pd.DataFrame, Tuple[pd.DataFrame, \u001b[38;5;28mstr\u001b[39m]],\n\u001b[32m      9\u001b[39m             target_feat: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     10\u001b[39m             feat_cfg: FeatureConfig = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     11\u001b[39m             pairwise_analysis: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     report = \u001b[43msweetviz\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataframeReport\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_feat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43mpairwise_analysis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m report\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sweetviz\\dataframe_report.py:277\u001b[39m, in \u001b[36mDataframeReport.__init__\u001b[39m\u001b[34m(self, source, target_feature_name, compare, pairwise_analysis, fc, verbosity)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features_to_process:\n\u001b[32m    275\u001b[39m     \u001b[38;5;66;03m# start = time.perf_counter()\u001b[39;00m\n\u001b[32m    276\u001b[39m     \u001b[38;5;28mself\u001b[39m.progress_bar.set_description_str(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFeature: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf.source.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28mself\u001b[39m._features[f.source.name] = \u001b[43msa\u001b[49m\u001b[43m.\u001b[49m\u001b[43manalyze_feature_to_dictionary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m     \u001b[38;5;28mself\u001b[39m.progress_bar.update(\u001b[32m1\u001b[39m)\n\u001b[32m    279\u001b[39m     \u001b[38;5;66;03m# print(f\"DONE FEATURE------> {f.source.name}\"\u001b[39;00m\n\u001b[32m    280\u001b[39m     \u001b[38;5;66;03m#       f\" {(time.perf_counter() - start):.2f}   {self._features[f.source.name]['type']}\")\u001b[39;00m\n\u001b[32m    281\u001b[39m \u001b[38;5;66;03m# self.progress_bar.set_description_str('[FEATURES DONE]')\u001b[39;00m\n\u001b[32m    282\u001b[39m \u001b[38;5;66;03m# self.progress_bar.close()\u001b[39;00m\n\u001b[32m    283\u001b[39m \n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# Wrap up summary\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sweetviz\\series_analyzer.py:142\u001b[39m, in \u001b[36manalyze_feature_to_dictionary\u001b[39m\u001b[34m(to_process)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;66;03m# Perform full analysis on source/compare/target\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m returned_feature_dict[\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m] == FeatureType.TYPE_NUM:\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     \u001b[43msweetviz\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseries_analyzer_numeric\u001b[49m\u001b[43m.\u001b[49m\u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_process\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturned_feature_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m returned_feature_dict[\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m] == FeatureType.TYPE_CAT:\n\u001b[32m    144\u001b[39m     sweetviz.series_analyzer_cat.analyze(to_process, returned_feature_dict)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sweetviz\\series_analyzer_numeric.py:102\u001b[39m, in \u001b[36manalyze\u001b[39m\u001b[34m(to_process, feature_dict)\u001b[39m\n\u001b[32m     98\u001b[39m     do_stats_numeric(to_process.compare, compare_dict)\n\u001b[32m    100\u001b[39m do_detail_numeric(to_process.source, to_process.source_counts, to_process.compare_counts, feature_dict)\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m feature_dict[\u001b[33m\"\u001b[39m\u001b[33mminigraph\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mGraphNumeric\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_process\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m feature_dict[\u001b[33m\"\u001b[39m\u001b[33mdetail_graphs\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlist\u001b[39m()\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m num_bins \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m0\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m15\u001b[39m, \u001b[32m30\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sweetviz\\graph_numeric.py:71\u001b[39m, in \u001b[36mGraphNumeric.__init__\u001b[39m\u001b[34m(self, which_graph, to_process)\u001b[39m\n\u001b[32m     67\u001b[39m     normalizing_weights = norm_source\n\u001b[32m     69\u001b[39m gap_percent = config[\u001b[33m\"\u001b[39m\u001b[33mGraphs\u001b[39m\u001b[33m\"\u001b[39m].getfloat(\u001b[33m\"\u001b[39m\u001b[33msummary_graph_categorical_gap\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m warnings.filterwarnings(\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, category=\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mVisibleDeprecationWarning\u001b[49m)\n\u001b[32m     72\u001b[39m \u001b[38;5;28mself\u001b[39m.hist_specs = axs.hist(plot_data, weights = normalizing_weights, bins=\u001b[38;5;28mself\u001b[39m.num_bins, \\\n\u001b[32m     73\u001b[39m                            rwidth = (\u001b[32m100.0\u001b[39m - gap_percent) / \u001b[32m100.0\u001b[39m)\n\u001b[32m     74\u001b[39m warnings.filterwarnings(\u001b[33m'\u001b[39m\u001b[33monce\u001b[39m\u001b[33m'\u001b[39m, category=np.VisibleDeprecationWarning)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\__init__.py:427\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr)\u001b[39m\n\u001b[32m    424\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchar\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchar\u001b[39;00m\n\u001b[32m    425\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m char.chararray\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m has no attribute \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    428\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\u001b[34m__name__\u001b[39m, attr))\n",
      "\u001b[31mAttributeError\u001b[39m: module 'numpy' has no attribute 'VisibleDeprecationWarning'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 290x120 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sweetviz as sv\n",
    "\n",
    "# Generate the report\n",
    "building_report = sv.analyze(building)\n",
    "\n",
    "# Extract key insights\n",
    "print(\"ðŸ”¹ Summary from the Report:\\n\")\n",
    "print(f\"âœ… Building_id is the primary key for this dataset.\")\n",
    "print(f\"âœ… Observations coming from {building.shape[0]} buildings.\")\n",
    "print(f\"âœ… Collinear Features: building_id and site_id are correlated.\")\n",
    "print(f\"âœ… Missing Values: More than 50% missing in 'floor_count' and 'year_built'.\")\n",
    "print(f\"âœ… Data Type Analysis: Except 'primary_use', all columns are numeric.\")\n",
    "print(f\"âœ… Most Common 'primary_use' Categories: {building['primary_use'].value_counts().nlargest(3).index.tolist()}.\")\n",
    "print(f\"âœ… Floor Count Distribution: Mostly between 1 to 5 floors.\")\n",
    "print(f\"âœ… Square Feet Analysis: Most buildings < 200,000 sq. ft., with some > 800,000 sq. ft.\")\n",
    "print(f\"âœ… Building Age: Data includes buildings from {int(building['year_built'].min())} to {int(building['year_built'].max())} (if no NaN values).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd0070-1900-47a8-9b17-6bd72815e09f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
